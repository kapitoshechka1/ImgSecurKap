{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6b7SUP7S56L",
        "outputId": "d5c45e76-1eaa-4359-adb4-ffcf06f1c677"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: adversarial-robustness-toolbox in /usr/local/lib/python3.10/dist-packages (1.17.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (67.7.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from adversarial-robustness-toolbox) (4.66.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (3.5.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Disable TensorFlow eager execution:\n",
        "import tensorflow as tf\n",
        "if tf.executing_eagerly():\n",
        "    tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# Load Keras dependencies:\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import load_img, img_to_array, array_to_img\n",
        "\n",
        "# Load ART dependencies:\n",
        "from art.estimators.classification import KerasClassifier\n",
        "import art.attacks.evasion as art\n",
        "from art.defences.preprocessor import SpatialSmoothing\n",
        "from art.utils import to_categorical\n",
        "\n",
        "from PIL import Image, ImageChops, ImageEnhance, ImageFilter\n",
        "from array import *\n",
        "import os"
      ],
      "metadata": {
        "id": "YP1ehawXTUMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check(pred, real):\n",
        "  label = decode_predictions(pred)\n",
        "  if label[0][0][1] == real:\n",
        "    check = 1\n",
        "  else:\n",
        "    check = 0\n",
        "  return check"
      ],
      "metadata": {
        "id": "ulH_IEMMTVqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50(weights='imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CxfaDCuTXSK",
        "outputId": "c8cc3aca-5f4b-4333-c567-46190eec1450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/src/layers/normalization/batch_normalization.py:883: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from art.preprocessing.preprocessing import Preprocessor\n",
        "\n",
        "class ResNet50Preprocessor(Preprocessor):\n",
        "\n",
        "    def __call__(self, x, y=None):\n",
        "        return preprocess_input(x.copy()), y\n",
        "\n",
        "    def estimate_gradient(self, x, gradient):\n",
        "        return gradient[..., ::-1]"
      ],
      "metadata": {
        "id": "h430fFhDTYsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ResNet50Preprocessor()\n",
        "classifier = KerasClassifier(clip_values=(0, 255), model=model, preprocessing=preprocessor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUMlAHV_TfeD",
        "outputId": "7bf04cd5-8d74-4676-cc93-0759895daee0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:art.estimators.classification.keras:Keras model has no loss set. Classifier tries to use `k.sparse_categorical_crossentropy`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory_path = '/content/'\n",
        "save_path = '/content/images'"
      ],
      "metadata": {
        "id": "4lq2x0v_Tg8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real = [[139, 'ruddy_turnstone'], [144, 'pelican'], [148, \"killer_whale\"], [149, \"dugong\"], [150, \"sea_lion\"], [152, \"Japanese_spaniel\"], [153, \"Maltese_dog\"], [154, \"Pekinese\"], [155, \"Shih-Tzu\"], [159, \"Rhodesian_ridgeback\"], [161, \"basset\"], [162, \"beagle\"], [164, \"bluetick\"], [166, \"Walker_hound\"], [168, \"redbone\"], [184, \"Irish_terrier\"], [185, \"Norfolk_terrier\"], [186, \"Norwich_terrier\"], [187, \"Yorkshire_terrier\"], [188, \"wire-haired_fox_terrier\"], [190, \"Sealyham_terrier\"], [191, \"Airedale\"], [193, \"Australian_terrier\"], [199, \"Scotch_terrier\"], [207, \"golden_retriever\"], [208, \"Labrador_retriever\"], [212, \"English_setter\"], [213, \"Irish_setter\"], [215, \"Brittany_spaniel\"], [222, \"kuvasz\"], [224, \"groenendael\"], [226, \"briard\"], [232, \"Border_collie\"], [234, \"Rottweiler\"], [240, \"Appenzeller\"], [241, \"EntleBucher\"], [243, \"bull_mastiff\"], [246, \"Great_Dane\"], [249, \"malamute\"], [250, \"Siberian_husky\"], [252, \"affenpinscher\"], [253, \"basenji\"], [254, \"pug\"], [255, \"Leonberg\"], [256, \"Newfoundland\"], [258, \"Samoyed\"], [259, \"Pomeranian\"], [261, \"keeshond\"], [262, \"Brabancon_griffon\"], [263, \"Pembroke\"], [219, \"cocker_spaniel\"], [266, \"miniature_poodle\"], [268, \"Mexican_hairless\"], [269, \"timber_wolf\"], [270, \"white_wolf\"], [272, \"coyote\"], [276, \"hyena\"], [277, \"red_fox\"], [279, \"Arctic_fox\"], [280, \"grey_fox\"], [281, \"tabby\"], [283, \"Persian_cat\"], [284, \"Siamese_cat\"], [285, \"Egyptian_cat\"], [287, \"lynx\"], [288, \"leopard\"], [289, \"snow_leopard\"], [290, \"jaguar\"], [291, \"lion\"], [292, \"tiger\"], [293, \"cheetah\"], [294, \"brown_bear\"], [295, \"American_black_bear\"], [296, \"ice_bear\"], [297, \"sloth_bear\"], [299, \"meerkat\"], [302, \"ground_beetle\"], [304, \"leaf_beetle\"], [305, \"dung_beetle\"], [306, \"rhinoceros_beetle\"], [307, \"weevil\"], [321, \"admiral\"], [323, \"monarch\"], [332, \"Angora\"], [333, \"hamster\"], [335, \"fox_squirrel\"], [336, \"marmot\"], [338, \"guinea_pig\"], [344, \"hippopotamus\"], [347, \"bison\"], [349, \"bighorn\"], [352, \"impala\"], [354, \"Arabian_camel\"], [358, \"polecat\"], [359, \"black-footed_ferret\"], [364, \"three-toed_sloth\"], [365, \"orangutan\"], [366, \"gorilla\"], [367, \"chimpanzee\"], [368, \"gibbon\"]]"
      ],
      "metadata": {
        "id": "hlN5uaaDTp3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_sum = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ],
      "metadata": {
        "id": "m68V-DyVUqUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESNET_MEAN = np.array([103.939, 116.779, 123.68])"
      ],
      "metadata": {
        "id": "9hla7klyhMhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eps = 1.\n",
        "delt = 0.1\n",
        "check_prob = 0.7"
      ],
      "metadata": {
        "id": "D0wfIEkfmEYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def orthogonal_perturbation(delta, prev_sample, target_sample, mask):\n",
        "\t\"\"\"Generate orthogonal perturbation.\"\"\"\n",
        "\tperturb = np.random.randn(1, 224, 224, 3)\n",
        "\tperturb /= np.linalg.norm(perturb, axis=(1, 2))\n",
        "\tperturb *= delta * np.mean(get_diff(target_sample, prev_sample))\n",
        "\t# Project perturbation onto sphere around target\n",
        "\tdiff = (target_sample - prev_sample).astype(np.float32) # Orthorgonal vector to sphere surface\n",
        "\tdiff /= get_diff(target_sample, prev_sample) # Orthogonal unit vector\n",
        "\t# We project onto the orthogonal then subtract from perturb\n",
        "\t# to get projection onto sphere surface\n",
        "\tperturb -= (np.vdot(perturb, diff) / np.linalg.norm(diff)**2) * diff\n",
        "\t# Check overflow and underflow\n",
        "\toverflow = (prev_sample + perturb) - 255 + RESNET_MEAN\n",
        "\tperturb -= overflow * (overflow > 0)\n",
        "\tunderflow = -RESNET_MEAN\n",
        "\tperturb += underflow * (underflow > 0)\n",
        "\tif np.any(mask):\n",
        "\t\tperturb *= (1 - mask)\n",
        "\treturn perturb"
      ],
      "metadata": {
        "id": "HdQYvQYhhPLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_perturbation(epsilon, prev_sample, target_sample, mask):\n",
        "\t\"\"\"Generate forward perturbation.\"\"\"\n",
        "\tperturb = (target_sample - prev_sample).astype(np.float32)\n",
        "\tperturb *= epsilon\n",
        "\t#if np.any(mask):\n",
        "\t\t#perturb *= (1 - mask)\n",
        "\treturn perturb"
      ],
      "metadata": {
        "id": "AVt-GXX5hTB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_converted_prediction(sample, classifier):\n",
        "\t\"\"\"\n",
        "\tThe original sample is dtype float32, but is converted\n",
        "\tto uint8 when exported as an image. The loss of precision\n",
        "\toften causes the label of the image to change, particularly\n",
        "\tbecause we are very close to the boundary of the two classes.\n",
        "\tThis function checks for the label of the exported sample\n",
        "\tby simulating the export process.\n",
        "\t\"\"\"\n",
        "\tsample = (sample + RESNET_MEAN).astype(np.uint8).astype(np.float32) - RESNET_MEAN\n",
        "\tlabel = decode_predictions(classifier.predict(sample), top=1)[0][0][1]\n",
        "\treturn label"
      ],
      "metadata": {
        "id": "kYzHoWo2hVCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(img):\n",
        "\t\"\"\"Load and preprocess image file.\"\"\"\n",
        "\tx = image.img_to_array(img)\n",
        "\tx = np.expand_dims(x, axis=0)\n",
        "\tx = preprocess_input(x)\n",
        "\treturn x"
      ],
      "metadata": {
        "id": "OdOzmY30hWGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_diff(sample_1, sample_2):\n",
        "\t\"\"\"Channel-wise norm of difference between samples.\"\"\"\n",
        "\treturn np.linalg.norm(sample_1 - sample_2, axis=(1, 2))"
      ],
      "metadata": {
        "id": "KIpXix_7hag0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_mask(image_shape, probability):\n",
        "  prob = 1 - probability\n",
        "# Создаем маску, заполненную нулями\n",
        "  mask = np.zeros(image_shape, dtype=np.float32)\n",
        "# Выполняем случайный выбор для каждого пикселя с вероятностью probability\n",
        "  for i in range(image_shape[1]):\n",
        "    for j in range(image_shape[2]):\n",
        "      if np.random.rand() < prob:\n",
        "        mask[0, i, j, :] = 1 # Устанавливаем все каналы пикселя в 1\n",
        "  return mask"
      ],
      "metadata": {
        "id": "1T8T7wTohdgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def restore_pixels(original_sample, perturbed_sample, mask):\n",
        "  restored_sample = original_sample * mask + perturbed_sample * (1 - mask)\n",
        "  return restored_sample"
      ],
      "metadata": {
        "id": "qEMKWKYahg9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_prediction(predictions):\n",
        "  labels = decode_predictions(predictions)\n",
        "  for i in range(5):\n",
        "    kind = labels[0][i][1].replace(\"_\", \" \").title()\n",
        "    percent = round(labels[0][i][2] * 100, 2)\n",
        "    print(f\"This is a {kind}. I am {percent} % sure.\")"
      ],
      "metadata": {
        "id": "qDkuMsVghj_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def boundary_attack(classifier, target_sample, folder_to_save, prob, epsilon, delta):\n",
        "\t# Load model, images and other parameters\n",
        "\t# classifier = ResNet50(weights='imagenet')\n",
        "\tinitial_sample = np.random.rand(1, 224, 224, 3)\n",
        "\t#target_sample = preprocess('/content/2.jpg')\n",
        "\t#folder = folder_to_save\n",
        "\t# save_image(np.copy(initial_sample), classifier, folder)\n",
        "\tattack_class = np.argmax(classifier.predict(target_sample))\n",
        "\t# print('Attack_class: ', attack_class)\n",
        "\tattack_prob = np.max(classifier.predict(target_sample))\n",
        "\t# print('Attack_prob: ', attack_prob)\n",
        "\t# target_class = np.argmax(classifier.predict(target_sample))\n",
        "\tmask = np.zeros((1, 224, 224, 3), dtype=np.float32)\n",
        "\tmin_diff = 2000\n",
        "\tvery_good_diff = 3000\n",
        "\tvery_good_adversarial_sample = None\n",
        "\tgood_adversarial_sample = None\n",
        "\tgood_diff = 3000\n",
        "\t# count_diff = 0\n",
        "\t# goods = []\n",
        "\n",
        "\tadversarial_sample = initial_sample\n",
        "\tn_steps = 0\n",
        "\tn_calls = 0\n",
        "\t# epsilon = 1.\n",
        "\t# delta = 0.1\n",
        "\n",
        "\t# Move first step to the boundary\n",
        "\twhile True:\n",
        "\t\ttrial_sample = adversarial_sample + forward_perturbation(epsilon, adversarial_sample, target_sample, mask)\n",
        "\t\tprediction = classifier.predict(trial_sample)\n",
        "\t\tn_calls += 1\n",
        "\t\tif np.argmax(prediction) != attack_class:\n",
        "\t\t\tadversarial_sample = trial_sample\n",
        "\t\t\tbreak\n",
        "\t\telse:\n",
        "\t\t\tepsilon *= 0.9\n",
        "\n",
        "\tmask_ort = generate_mask((1, 224, 224, 3), prob)\n",
        "\tadversarial_sample = restore_pixels(target_sample, adversarial_sample, mask_ort)\n",
        "\t# Iteratively run attack\n",
        "\twhile True:\n",
        "\t\t# print(\"Step #{}...\".format(n_steps))\n",
        "\t\t# Orthogonal step\n",
        "\t\t# print(\"\\tDelta step...\")\n",
        "\t\td_step = 0\n",
        "\t\twhile True:\n",
        "\t\t\td_step += 1\n",
        "\t\t\t# print(\"\\t#{}\".format(d_step))\n",
        "\t\t\ttrial_samples = []\n",
        "\t\t\t#mask = generate_mask((1, 224, 224, 3), 0.85)\n",
        "\t\t\tfor i in np.arange(10):\n",
        "\t\t\t\ttrial_sample = adversarial_sample + orthogonal_perturbation(delta, adversarial_sample, target_sample, mask_ort)\n",
        "\t\t\t\ttrial_samples.append(trial_sample)\n",
        "\t\t\ttrial_samples_combined = np.concatenate(trial_samples, axis=0)\n",
        "\t\t\tpredictions = classifier.predict(trial_samples_combined)\n",
        "\t\t\tn_calls += 10\n",
        "\t\t\t# print(np.max(predictions, axis=1))\n",
        "\t\t\tpredictions = np.argmax(predictions, axis=1)\n",
        "\t\t\tpredictions_prob = np.max(predictions)\n",
        "\t\t\td_1 = np.mean((predictions != attack_class) & (abs(predictions - attack_class) < 30))\n",
        "\t\t\t#print(d_1)\n",
        "\t\t\td_2 = np.mean((predictions == attack_class) & ((attack_prob - predictions_prob) > 5))\n",
        "\t\t\td_score = d_1 + d_2\n",
        "\t\t\tif d_score > 0.0:\n",
        "\t\t\t\tif d_score < 0.3:\n",
        "\t\t\t\t\tdelta *= 0.9\n",
        "\t\t\t\telif d_score > 0.7:\n",
        "\t\t\t\t\tdelta /= 0.9\n",
        "\t\t\t\t#adversarial_sample = np.array(trial_samples)[np.where(predictions != attack_class)[0][0]]\n",
        "\t\t\t\tadversarial_sample = np.array(trial_samples)[np.where(((predictions != attack_class) & (abs(predictions - attack_class) < 30))|((predictions == attack_class)&((attack_prob - predictions_prob) > 5)))[0][0]]\n",
        "\t\t\t\tbreak\n",
        "\t\t\telse:\n",
        "\t\t\t\t# print('Delta = ', delta)\n",
        "\t\t\t\tdelta *= 0.9\n",
        "\t\t\tif d_step > 250:\n",
        "\t\t\t\tbreak\n",
        "\t\t# Forward step\n",
        "\t\t# print(\"\\tEpsilon step...\")\n",
        "\t\te_step = 0\n",
        "\t\twhile True:\n",
        "\t\t\te_step += 1\n",
        "\t\t\t# print(\"\\t#{}\".format(e_step))\n",
        "\t\t\tmask = np.zeros((1, 224, 224, 3), dtype=np.float32)\n",
        "\t\t\ttrial_sample = adversarial_sample + forward_perturbation(epsilon, adversarial_sample, target_sample, mask)\n",
        "\t\t\tprediction = classifier.predict(trial_sample)\n",
        "\t\t\t# print(np.argmax(prediction))\n",
        "\t\t\tn_calls += 1\n",
        "\t\t\tif (((np.argmax(prediction) != attack_class) & (abs(np.argmax(prediction) - attack_class) < 30))|((np.argmax(prediction) == attack_class)&((attack_prob - np.max(prediction)) > 5))):\n",
        "\t\t\t#if np.argmax(prediction) != attack_class:\n",
        "\t\t\t\tadversarial_sample = trial_sample\n",
        "\t\t\t\tepsilon /= 0.5\n",
        "\t\t\t\tbreak\n",
        "\t\t\telif e_step > 250:\n",
        "\t\t\t\t\tbreak\n",
        "\t\t\telse:\n",
        "\t\t\t\tepsilon *= 0.5\n",
        "\n",
        "\t\tn_steps += 1\n",
        "\t\t#chkpts = [1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80, 90, 100, 150, 200, 500]\n",
        "\t\t#adversarial_sample = restore_pixels(target_sample, adversarial_sample, mask)\n",
        "\t\t#if (n_steps in chkpts) or (n_steps % 500 == 0):\n",
        "\t\t\t#print(\"{} steps\".format(n_steps))\n",
        "\t\t\t#print(\"Original:\")\n",
        "\t\t\t#print_prediction(classifier.predict(target_sample))\n",
        "\t\t\t#print(\"Adversarial:\")\n",
        "\t\t\t#print_prediction(classifier.predict(adversarial_sample))\n",
        "\t\t\t#save_image(np.copy(adversarial_sample), classifier, folder)\n",
        "\t\t\t#diff = np.mean(get_diff(adversarial_sample, target_sample))\n",
        "\t\t\t#print('Difference: ', diff)\n",
        "\t\tdiff = np.mean(get_diff(adversarial_sample, target_sample))\n",
        "\t\t#print('Diff: ', diff)\n",
        "\t\t#print('Good_diff: ', good_diff)\n",
        "\t\tif ((diff <= very_good_diff) & (np.argmax(prediction) != attack_class) & (diff >= min_diff)):\n",
        "\t\t\tvery_good_diff = diff\n",
        "\t\t\tvery_good_adversarial_sample = adversarial_sample\n",
        "\t\tif ((diff <= good_diff) & (diff >= min_diff)):\n",
        "\t\t\tgood_diff = diff\n",
        "\t\t\tgood_adversarial_sample = adversarial_sample\n",
        "\t\tif e_step > 250:\n",
        "\t\t\t# print(\"{} steps\".format(n_steps))\n",
        "\t\t\t# print(\"Mean Squared Error: {}\".format(diff))\n",
        "\t\t\t# save_image(np.copy(adversarial_sample), classifier, folder)\n",
        "\t\t\tbreak\n",
        "\t\tif n_steps > 100:\n",
        "\t\t\t#print(\"{} steps\".format(n_steps))\n",
        "\t\t\t# save_image(np.copy(adversarial_sample), classifier, folder)\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\t# print(\"Mean Squared Error: {}\".format(diff))\n",
        "\t\t# print(\"Calls: {}\".format(n_calls))\n",
        "\t\t# print(\"Attack Class: {}\".format(attack_class))\n",
        "\t\t# print(\"Target Class: {}\".format(target_class))\n",
        "\t\t# print(\"Adversarial Class: {}\".format(np.argmax(prediction)))\n",
        "\t\t# print('Good: ', count_diff)\n",
        "\n",
        "\tif (very_good_adversarial_sample is not None):\n",
        "\t\t#print(\"Difference: {}\".format(np.mean(get_diff(very_good_adversarial_sample, target_sample))))\n",
        "\t\t#print(\"Original:\")\n",
        "\t\t#print_prediction(classifier.predict(target_sample))\n",
        "\t\t#print(\"Adversarial:\")\n",
        "\t\t#print_prediction(classifier.predict(very_good_adversarial_sample))\n",
        "\t\t#label = get_converted_prediction(np.copy(very_good_adversarial_sample), classifier)\n",
        "\t\t#very_good_adversarial_sample_img = very_good_adversarial_sample[0]\n",
        "\t\t#very_good_adversarial_sample_img += RESNET_MEAN\n",
        "\t\t#very_good_adversarial_sample_img = very_good_adversarial_sample_img[..., ::-1].astype(np.uint8)\n",
        "\t\t#very_good_adversarial_sample_img = Image.fromarray(very_good_adversarial_sample_img)\n",
        "\t\t#very_good_adversarial_sample_img.save(os.path.join(\"images\", folder, \"{}_{}_{}.jpg\".format('Very_good', label, prob)))\n",
        "\t\treturn very_good_adversarial_sample\n",
        "\telif (good_adversarial_sample is not None):\n",
        "\t\t#print(\"Difference: {}\".format(np.mean(get_diff(good_adversarial_sample, target_sample))))\n",
        "\t\t#print(\"Original:\")\n",
        "\t\t#print_prediction(classifier.predict(target_sample))\n",
        "\t\t#print(\"Adversarial:\")\n",
        "\t\t#print_prediction(classifier.predict(good_adversarial_sample))\n",
        "\t\t#label = get_converted_prediction(np.copy(good_adversarial_sample), classifier)\n",
        "\t\t#good_adversarial_sample_img = good_adversarial_sample[0]\n",
        "\t\t#good_adversarial_sample_img += RESNET_MEAN\n",
        "\t\t#good_adversarial_sample_img = good_adversarial_sample_img[..., ::-1].astype(np.uint8)\n",
        "\t\t#good_adversarial_sample_img = Image.fromarray(good_adversarial_sample_img)\n",
        "\t\t#good_adversarial_sample_img.save(os.path.join(\"images\", folder, \"{}_{}_{}.jpg\".format('Good', label, prob)))\n",
        "\t\treturn good_adversarial_sample\n",
        "\telse:\n",
        "\t\t#print(\"Difference: {}\".format(np.mean(get_diff(adversarial_sample, target_sample))))\n",
        "\t\t#print(\"Original:\")\n",
        "\t\t#print_prediction(classifier.predict(target_sample))\n",
        "\t\t#print(\"Adversarial:\")\n",
        "\t\t#print_prediction(classifier.predict(adversarial_sample))\n",
        "\t\t#label = get_converted_prediction(np.copy(adversarial_sample), classifier)\n",
        "\t\t#adversarial_sample_img = adversarial_sample[0]\n",
        "\t\t#adversarial_sample_img += RESNET_MEAN\n",
        "\t\t#adversarial_sample_img = adversarial_sample_img[..., ::-1].astype(np.uint8)\n",
        "\t\t#adversarial_sample_img = Image.fromarray(adversarial_sample_img)\n",
        "\t\t#adversarial_sample_img.save(os.path.join(\"images\", folder, \"{}_{}_{}.jpg\".format('NotGood', label, prob)))\n",
        "\t\treturn adversarial_sample"
      ],
      "metadata": {
        "id": "yUM8R6_Xhmms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = load_img('/content/2.jpg', target_size=(224, 224))\n",
        "x = np.expand_dims(img.copy(), axis=0)\n",
        "x = preprocess_input(x)\n",
        "x_art = np.expand_dims(img, axis=0)\n",
        "adv = art.SimBA(classifier, max_iter = 600, epsilon = 100)\n",
        "x_art_adv = adv.generate(x_art)\n",
        "adv_img = (x_art_adv + 255) / 2\n",
        "adv_img = adv_img.reshape(224, 224, 3)\n",
        "adv_image = array_to_img(adv_img)\n",
        "r, g, b = adv_image.split()\n",
        "adv_image = Image.merge(\"RGB\", (r, g, b))\n",
        "target_boundary = preprocess(adv_image)\n",
        "adv_Boundary = boundary_attack(model, target_boundary, save_path, check_prob, eps, delt)\n",
        "adversarial_sample_img = adv_Boundary[0]\n",
        "adversarial_sample_img += RESNET_MEAN\n",
        "adversarial_sample_img = adversarial_sample_img[..., ::-1].astype(np.uint8)\n",
        "advs_img = Image.fromarray(adversarial_sample_img)"
      ],
      "metadata": {
        "id": "RCUJFlflgQ3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = load_img('/content/1.jpg', target_size=(224, 224))\n",
        "x = np.expand_dims(img.copy(), axis=0)\n",
        "x = preprocess_input(x)\n",
        "x_art = np.expand_dims(img, axis=0)\n",
        "adv = art.SimBA(classifier, max_iter = 600, epsilon = 100)\n",
        "x_art_adv = adv.generate(x_art)\n",
        "adv_img = (x_art_adv + 255) / 2\n",
        "adv_img = adv_img.reshape(224, 224, 3)\n",
        "adv_image = array_to_img(adv_img)\n",
        "r, g, b = adv_image.split()\n",
        "adv_image = Image.merge(\"RGB\", (r, g, b))\n",
        "target_boundary = preprocess(adv_image)\n",
        "adv_Boundary = boundary_attack(model, target_boundary, save_path, check_prob, eps, delt)\n",
        "adversarial_sample_img = adv_Boundary[0]\n",
        "adversarial_sample_img += RESNET_MEAN\n",
        "adversarial_sample_img = adversarial_sample_img[..., ::-1].astype(np.uint8)\n",
        "advs_img = Image.fromarray(adversarial_sample_img)"
      ],
      "metadata": {
        "id": "8cjvbFK3kpSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 101):\n",
        "  file_name = f\"{i}.jpg\"\n",
        "  file_path = os.path.join(directory_path, file_name)\n",
        "  if os.path.exists(file_path):\n",
        "    img = load_img(file_path, target_size=(224, 224))\n",
        "    x_art = np.expand_dims(img, axis=0)\n",
        "    adv = art.SimBA(classifier, max_iter = 600, epsilon = 100)\n",
        "    x_art_adv = adv.generate(x_art)\n",
        "    adv_img = (x_art_adv + 255) / 2\n",
        "    adv_img = adv_img.reshape(224, 224, 3)\n",
        "    adv_image = array_to_img(adv_img)\n",
        "    r, g, b = adv_image.split()\n",
        "    adv_image = Image.merge(\"RGB\", (r, g, b))\n",
        "    target_boundary = preprocess(adv_image)\n",
        "    adv_Boundary = boundary_attack(model, target_boundary, save_path, check_prob, eps, delt)\n",
        "    adversarial_sample_img = adv_Boundary[0]\n",
        "    adversarial_sample_img += RESNET_MEAN\n",
        "    adversarial_sample_img = adversarial_sample_img[..., ::-1].astype(np.uint8)\n",
        "    advs_img = Image.fromarray(adversarial_sample_img)\n",
        "    enhancer_bright = ImageEnhance.Brightness(advs_img)\n",
        "    enhancer_color = ImageEnhance.Color(advs_img)\n",
        "    im_rotate_1 = advs_img.rotate(15, expand=True)\n",
        "    im_rotate_1.save(\"/content/mod_images/1_1.jpg\")\n",
        "    img_rotate_1 = load_img(\"/content/mod_images/1_1.jpg\", target_size=(224, 224))\n",
        "    img_rotate_1_art = np.expand_dims(img_rotate_1, axis=0)\n",
        "    pred_1 = classifier.predict(img_rotate_1_art)\n",
        "    check_sum[0] += check(pred_1, real[i-1][1])\n",
        "    im_rotate_2 = advs_img.rotate(345, expand=True)\n",
        "    im_rotate_2.save(\"/content/mod_images/1_2.jpg\")\n",
        "    img_rotate_2 = load_img(\"/content/mod_images/1_2.jpg\", target_size=(224, 224))\n",
        "    img_rotate_2_art = np.expand_dims(img_rotate_2, axis=0)\n",
        "    pred_2 = classifier.predict(img_rotate_2_art)\n",
        "    check_sum[1] += check(pred_2, real[i-1][1])\n",
        "    light_img = enhancer_bright.enhance(1.5)\n",
        "    light_img_art = np.expand_dims(light_img, axis=0)\n",
        "    pred_3 = classifier.predict(light_img_art)\n",
        "    check_sum[2] += check(pred_3, real[i-1][1])\n",
        "    dark_img = enhancer_bright.enhance(0.5)\n",
        "    dark_img_art = np.expand_dims(dark_img, axis=0)\n",
        "    pred_4 = classifier.predict(dark_img_art)\n",
        "    check_sum[3] += check(pred_4, real[i-1][1])\n",
        "    small_img = advs_img.resize((100, 100))\n",
        "    small_img.save(\"/content/mod_images/1_3.jpg\")\n",
        "    small_img = load_img(\"/content/mod_images/1_3.jpg\", target_size=(224, 224))\n",
        "    small_img_art = np.expand_dims(small_img, axis=0)\n",
        "    pred_5 = classifier.predict(small_img_art)\n",
        "    check_sum[4] += check(pred_5, real[i-1][1])\n",
        "    big_img = advs_img.resize((1000, 1000))\n",
        "    big_img.save(\"/content/mod_images/1_4.jpg\")\n",
        "    big_img = load_img(\"/content/mod_images/1_4.jpg\", target_size=(224, 224))\n",
        "    big_img_art = np.expand_dims(big_img, axis=0)\n",
        "    pred_6 = classifier.predict(big_img_art)\n",
        "    check_sum[5] += check(pred_6, real[i-1][1])\n",
        "    bright_img = enhancer_color.enhance(1.5)\n",
        "    bright_img_art = np.expand_dims(bright_img, axis=0)\n",
        "    pred_7 = classifier.predict(bright_img_art)\n",
        "    check_sum[6] += check(pred_7, real[i-1][1])\n",
        "    chb_img = enhancer_color.enhance(0.0)\n",
        "    chb_img_art = np.expand_dims(chb_img, axis=0)\n",
        "    pred_8 = classifier.predict(chb_img_art)\n",
        "    check_sum[7] += check(pred_8, real[i-1][1])\n",
        "    clear_img = advs_img.filter(ImageFilter.SHARPEN)\n",
        "    clear_img_art = np.expand_dims(clear_img, axis=0)\n",
        "    pred_9 = classifier.predict(clear_img_art)\n",
        "    check_sum[8] += check(pred_9, real[i-1][1])\n",
        "    blurry_img = advs_img.filter(ImageFilter.GaussianBlur(radius=0.7))\n",
        "    blurry_img_art = np.expand_dims(blurry_img, axis=0)\n",
        "    pred_10 = classifier.predict(blurry_img_art)\n",
        "    check_sum[9] += check(pred_10, real[i-1][1])\n",
        "    print(check_sum)\n",
        "print(check_sum)\n",
        "SimBA_Boundary_result = 0\n",
        "for i in range(0, 10):\n",
        "  SimBA_Boundary_result += check_sum[i]\n",
        "print(\"Среднее для атаки SimBA+Boundary: \", SimBA_Boundary_result / 1000)"
      ],
      "metadata": {
        "id": "6iitHZBBT807"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
